{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação para Algoritmos de Clustering\n",
    "\n",
    "Neste notebook, exploraremos diversas métricas utilizadas para avaliar a qualidade dos resultados de algoritmos de clustering. Como o clustering é uma tarefa de aprendizado não supervisionado, a avaliação de seus resultados é um desafio, pois geralmente não dispomos de rótulos verdadeiros (*ground truth*). Portanto, focaremos em métricas internas, que avaliam a qualidade da estrutura dos clusters baseando-se apenas nos dados e na partição gerada.\n",
    "\n",
    "## Conteúdos Abordados\n",
    "\n",
    "1.  **Geração de Datasets Sintéticos**: Criação de conjuntos de dados com diferentes estruturas geométricas para testar os algoritmos.\n",
    "2.  **Aplicação de Algoritmos de Clustering**: Utilização dos algoritmos K-Means, Hierárquico Aglomerativo e DBSCAN nos datasets.\n",
    "3.  **Métricas de Avaliação Interna**:\n",
    "    * Introdução teórica e matemática de cada métrica.\n",
    "    * Implementação manual das funções para cálculo.\n",
    "    * **Silhouette Score**\n",
    "    * **Davies-Bouldin Index (DBI)**\n",
    "    * **Dunn Index**\n",
    "4.  **Análise Comparativa**: Avaliação e comparação dos resultados dos algoritmos em cada dataset utilizando as métricas implementadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_circles, make_moons\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "import pandas as pd\n",
    "\n",
    "# Configurações para reprodutibilidade e visualização\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Geração de Datasets Sintéticos\n",
    "\n",
    "Para avaliar a eficácia dos algoritmos e das métricas, utilizaremos datasets sintéticos com características distintas. Isso nos permite visualizar e entender intuitivamente como cada algoritmo se comporta em diferentes topologias de dados.\n",
    "\n",
    "* **Blobs**: Clusters esféricos e bem separados, um cenário ideal para algoritmos baseados em centroides como o K-Means.\n",
    "* **Circles**: Clusters concêntricos, um desafio para algoritmos que assumem convexidade.\n",
    "* **Moons**: Clusters não convexos e com formas complexas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração dos datasets\n",
    "X_blobs, y_blobs = make_blobs(n_samples=300, centers=4, cluster_std=0.8, random_state=42)\n",
    "X_circles, y_circles = make_circles(n_samples=300, noise=0.1, factor=0.4, random_state=42)\n",
    "X_moons, y_moons = make_moons(n_samples=300, noise=0.1, random_state=42)\n",
    "\n",
    "# Normalização dos dados para que os algoritmos baseados em distância funcionem corretamente\n",
    "X_blobs = StandardScaler().fit_transform(X_blobs)\n",
    "X_circles = StandardScaler().fit_transform(X_circles)\n",
    "X_moons = StandardScaler().fit_transform(X_moons)\n",
    "\n",
    "# Dicionário para armazenar os datasets\n",
    "datasets = {\n",
    "    'Blobs': (X_blobs, y_blobs),\n",
    "    'Circles': (X_circles, y_circles),\n",
    "    'Moons': (X_moons, y_moons)\n",
    "}\n",
    "\n",
    "# Visualização dos datasets originais (ground truth)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Ground Truth dos Datasets Sintéticos', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, (name, (X, y)) in enumerate(datasets.items()):\n",
    "    axes[i].scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=50, alpha=0.8)\n",
    "    axes[i].set_title(name, fontsize=14)\n",
    "    axes[i].set_xlabel('Feature 1')\n",
    "    axes[i].set_ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Aplicação de Algoritmos de Clustering\n",
    "\n",
    "Agora, aplicaremos três algoritmos de clustering populares a cada um dos datasets gerados. Os parâmetros de cada algoritmo foram ajustados para corresponder ao número esperado de clusters ou às características dos dados.\n",
    "\n",
    "* **K-Means**: Define `n_clusters`.\n",
    "* **Hierárquico Aglomerativo**: Define `n_clusters`.\n",
    "* **DBSCAN**: Define `eps` (distância máxima entre dois pontos para serem considerados vizinhos) e `min_samples` (número mínimo de pontos para formar uma região densa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração dos algoritmos\n",
    "kmeans_params = {'n_clusters': 0, 'random_state': 42}\n",
    "agglomerative_params = {'n_clusters': 0}\n",
    "dbscan_params = {'eps': 0.3, 'min_samples': 4}\n",
    "\n",
    "# Dicionário para armazenar os resultados\n",
    "clustering_results = {}\n",
    "\n",
    "for name, (X, y) in datasets.items():\n",
    "    n_clusters = len(np.unique(y))\n",
    "    kmeans_params['n_clusters'] = n_clusters\n",
    "    agglomerative_params['n_clusters'] = n_clusters\n",
    "\n",
    "    # K-Means\n",
    "    kmeans = KMeans(**kmeans_params)\n",
    "    kmeans_labels = kmeans.fit_predict(X)\n",
    "\n",
    "    # Agglomerative Clustering\n",
    "    agglomerative = AgglomerativeClustering(**agglomerative_params)\n",
    "    agglomerative_labels = agglomerative.fit_predict(X)\n",
    "\n",
    "    # DBSCAN\n",
    "    dbscan = DBSCAN(**dbscan_params)\n",
    "    dbscan_labels = dbscan.fit_predict(X)\n",
    "\n",
    "    clustering_results[name] = {\n",
    "        'K-Means': kmeans_labels,\n",
    "        'Agglomerative': agglomerative_labels,\n",
    "        'DBSCAN': dbscan_labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização dos resultados\n",
    "fig, axes = plt.subplots(len(datasets), 3, figsize=(18, 15))\n",
    "fig.suptitle('Resultados dos Algoritmos de Clustering', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, (dataset_name, results) in enumerate(clustering_results.items()):\n",
    "    X, _ = datasets[dataset_name]\n",
    "    for j, (algo_name, labels) in enumerate(results.items()):\n",
    "        ax = axes[i, j]\n",
    "        # Pontos de ruído (-1) em preto para DBSCAN\n",
    "        unique_labels = set(labels)\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "        for k, col in zip(unique_labels, colors):\n",
    "            if k == -1:\n",
    "                col = [0, 0, 0, 1]  # Preto para ruído\n",
    "\n",
    "            class_member_mask = (labels == k)\n",
    "            xy = X[class_member_mask]\n",
    "            ax.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "                    markeredgecolor='k', markersize=8, alpha=0.8)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_title(algo_name, fontsize=14)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(dataset_name, fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Métricas de Avaliação Interna\n",
    "\n",
    "Nesta seção, detalharemos e implementaremos as métricas internas para avaliar a qualidade dos clusters sem usar os rótulos verdadeiros.\n",
    "\n",
    "## Silhouette Score\n",
    "\n",
    "O Silhouette Score mede quão similar um objeto é ao seu próprio cluster (coesão) em comparação com outros clusters (separação). A pontuação varia de -1 a +1, onde um valor alto indica que o objeto está bem combinado ao seu próprio cluster e mal combinado aos clusters vizinhos.\n",
    "\n",
    "### Formulação Matemática\n",
    "\n",
    "Para um único ponto de dados $i$, o score de silhueta $s(i)$ é calculado como:\n",
    "\n",
    "$$ s(i) = \\frac{b(i) - a(i)}{\\max\\{a(i), b(i)\\}} $$\n",
    "\n",
    "Onde:\n",
    "- $a(i)$ é a distância média de $i$ para todos os outros pontos no mesmo cluster (coesão intra-cluster).\n",
    "$$ a(i) = \\frac{1}{|C_k| - 1} \\sum_{j \\in C_k, i \\neq j} d(i, j) $$\n",
    "em que $i \\in C_k$.\n",
    "- $b(i)$ é a menor distância média de $i$ para todos os pontos em qualquer outro cluster, do qual $i$ não é membro (separação inter-cluster).\n",
    "$$ b(i) = \\min_{m \\neq k} \\left( \\frac{1}{|C_m|} \\sum_{j \\in C_m} d(i, j) \\right) $$\n",
    "\n",
    "O Silhouette Score para todo o dataset é a média de $s(i)$ sobre todos os pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_score(X, labels):\n",
    "    \"\"\"\n",
    "    Calcula o Silhouette Score para um conjunto de dados e seus rótulos de cluster.\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    \n",
    "    # Calcula a matriz de distâncias par a par\n",
    "    distances = cdist(X, X)\n",
    "    \n",
    "    silhouette_vals = []\n",
    "    for i in range(n_samples):\n",
    "        # Coesão (a_i)\n",
    "        cluster_i_mask = (labels == labels[i])\n",
    "        cluster_i_mask[i] = False # Exclui o próprio ponto\n",
    "        \n",
    "        if np.sum(cluster_i_mask) == 0:\n",
    "            a_i = 0 # Se o ponto é o único no cluster\n",
    "        else:\n",
    "            a_i = np.mean(distances[i][cluster_i_mask])\n",
    "\n",
    "        # Separação (b_i)\n",
    "        b_i = np.inf\n",
    "        for label_k in np.unique(labels):\n",
    "            if label_k != labels[i]:\n",
    "                cluster_k_mask = (labels == label_k)\n",
    "                mean_dist_k = np.mean(distances[i][cluster_k_mask])\n",
    "                if mean_dist_k < b_i:\n",
    "                    b_i = mean_dist_k\n",
    "        \n",
    "        # Score de silhueta para o ponto i\n",
    "        s_i = (b_i - a_i) / max(a_i, b_i)\n",
    "        silhouette_vals.append(s_i)\n",
    "        \n",
    "    return np.mean(silhouette_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Davies-Bouldin Index (DBI)\n",
    "\n",
    "O Davies-Bouldin Index é definido como a similaridade média de cada cluster com seu cluster mais similar. A similaridade é uma medida que compara a distância intra-cluster com a distância inter-cluster. Valores mais baixos do DBI indicam um melhor clustering.\n",
    "\n",
    "### Formulação Matemática\n",
    "\n",
    "O índice é calculado como:\n",
    "\n",
    "$$ DBI = \\frac{1}{K} \\sum_{k=1}^{K} \\max_{m \\neq k} \\left( R_{km} \\right) $$\n",
    "\n",
    "Onde $K$ é o número de clusters e $R_{km}$ é a medida de similaridade entre o cluster $C_k$ e o cluster $C_m$:\n",
    "\n",
    "$$ R_{km} = \\frac{S_k + S_m}{D_{km}} $$\n",
    "\n",
    "- $S_k$ é a dispersão média intra-cluster (distância média de cada ponto ao centroide do cluster $C_k$).\n",
    "$$ S_k = \\left( \\frac{1}{|C_k|} \\sum_{x \\in C_k} \\|x - \\mu_k\\|^2 \\right)^{1/2} $$\n",
    "em que $\\mu_k$ é o centroide de $C_k$.\n",
    "- $D_{km}$ é a distância entre os centroides dos clusters $C_k$ e $C_m$.\n",
    "$$ D_{km} = \\|\\mu_k - \\mu_m\\|_2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def davies_bouldin_score(X, labels):\n",
    "    \"\"\"\n",
    "    Calcula o Davies-Bouldin Index para um conjunto de dados e seus rótulos.\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(labels)\n",
    "    unique_labels = unique_labels[unique_labels != -1]  # remove outliers\n",
    "    \n",
    "    # Calcula centroides e dispersões de cada cluster\n",
    "    centroids = np.array([X[labels == i].mean(axis=0) for i in unique_labels])\n",
    "    dispersions = np.array([\n",
    "        np.mean(cdist(X[labels == i], [centroids[idx]])) \n",
    "        for idx, i in enumerate(unique_labels)\n",
    "    ])\n",
    "\n",
    "    # Calcula a máxima similaridade entre clusters\n",
    "    db_index = 0\n",
    "    for i in range(n_clusters):\n",
    "        max_similarity = -np.inf\n",
    "        for j in range(n_clusters):\n",
    "            if i != j:\n",
    "                dist_centroids = np.linalg.norm(centroids[i] - centroids[j])\n",
    "                similarity = (dispersions[i] + dispersions[j]) / dist_centroids\n",
    "                max_similarity = max(max_similarity, similarity)\n",
    "        db_index += max_similarity\n",
    "\n",
    "    return db_index / n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dunn Index\n",
    "\n",
    "O Dunn Index visa identificar clusters que são compactos e bem separados. Ele é definido como a razão entre a mínima distância inter-cluster e a máxima distância intra-cluster. Um valor mais alto do Dunn Index significa um melhor clustering.\n",
    "\n",
    "### Formulação Matemática\n",
    "\n",
    "O índice é dado por:\n",
    "\n",
    "$$ D = \\frac{\\min_{1 \\le k < m \\le K} d(C_k, C_m)}{\\max_{1 \\le l \\le K} \\text{diam}(C_l)} $$\n",
    "\n",
    "Onde:\n",
    "- $d(C_k, C_m)$ é a distância entre os clusters $C_k$ e $C_m$ (distância inter-cluster), que pode ser definida de várias formas (e.g., distância entre centroides). Usaremos a distância mínima entre quaisquer dois pontos de clusters diferentes.\n",
    "$$ d(C_k, C_m) = \\min_{x \\in C_k, y \\in C_m} \\|x - y\\|_2 $$\n",
    "- $\\text{diam}(C_l)$ é o diâmetro do cluster $C_l$ (distância intra-cluster máxima), definido como a maior distância entre quaisquer dois pontos no mesmo cluster.\n",
    "$$ \\text{diam}(C_l) = \\max_{x, y \\in C_l} \\|x - y\\|_2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dunn_index(X, labels):\n",
    "    \"\"\"\n",
    "    Calcula o Dunn Index para um conjunto de dados e seus rótulos.\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(labels)\n",
    "    pairwise_dists = squareform(pdist(X))\n",
    "\n",
    "    # Máxima distância intra-cluster\n",
    "    max_intra = 0\n",
    "    for lab in unique_labels:\n",
    "        idx = np.where(labels == lab)[0]\n",
    "        if len(idx) > 1:\n",
    "            d = np.max(pairwise_dists[np.ix_(idx, idx)])\n",
    "            if d > max_intra:\n",
    "                max_intra = d\n",
    "\n",
    "    if max_intra == 0:\n",
    "        return np.inf\n",
    "\n",
    "    # Mínima distância inter-cluster\n",
    "    min_inter = np.inf\n",
    "    for i in range(len(unique_labels)):\n",
    "        for j in range(i + 1, len(unique_labels)):\n",
    "            idx_i = np.where(labels == unique_labels[i])[0]\n",
    "            idx_j = np.where(labels == unique_labels[j])[0]\n",
    "            d = np.min(pairwise_dists[np.ix_(idx_i, idx_j)])\n",
    "            if d < min_inter:\n",
    "                min_inter = d\n",
    "\n",
    "    return min_inter / max_intra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Análise Comparativa\n",
    "\n",
    "Finalmente, vamos calcular cada métrica para cada combinação de dataset e algoritmo para avaliar e comparar os resultados.\n",
    "\n",
    "* **Silhouette Score**: Quanto maior, melhor.\n",
    "* **Davies-Bouldin Index**: Quanto menor, melhor.\n",
    "* **Dunn Index**: Quanto maior, melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = []\n",
    "\n",
    "for dataset_name, results in clustering_results.items():\n",
    "    X, _ = datasets[dataset_name]\n",
    "    for algo_name, labels in results.items():\n",
    "        silhouette = silhouette_score(X, labels)\n",
    "        dbi = davies_bouldin_score(X, labels)\n",
    "        dunn = dunn_index(X, labels)\n",
    "\n",
    "        evaluation_results.append({\n",
    "            'Dataset': dataset_name,\n",
    "            'Algorithm': algo_name,\n",
    "            'Silhouette Score': silhouette,\n",
    "            'Davies-Bouldin Index': dbi,\n",
    "            'Dunn Index': dunn\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame para visualização\n",
    "results_df = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Dicionário de formatação apenas para colunas numéricas\n",
    "formatter = {\n",
    "    'Silhouette Score': '{:.3f}',\n",
    "    'Davies-Bouldin Index': '{:.3f}',\n",
    "    'Dunn Index': '{:.3f}'\n",
    "}\n",
    "\n",
    "# Aplicar o estilo e a formatação seletiva\n",
    "results_df_styled = results_df.style.background_gradient(\n",
    "    cmap='viridis', subset=['Silhouette Score', 'Dunn Index']\n",
    ").background_gradient(\n",
    "    cmap='viridis_r', subset=['Davies-Bouldin Index']\n",
    ").format(formatter)\n",
    "\n",
    "display(results_df_styled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
